{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "copyright"
   },
   "source": [
    "#### Copyright 2019 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTI6TJZfOdZH"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZfzpqO9atfK"
   },
   "source": [
    "# Classification with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8pjZcxYWZ8Y"
   },
   "source": [
    "It's time to take what we've learned about the concepts of classification and see how software tools help us to accomplish this task using software.\n",
    "For this Colab, we will be using a Python library called Scikit-learn. Scikit-learn is a Machine-Learning library for Python built on top of numpy that provides a\n",
    "lot of functionality for classification, regression, clustering and many other Machine-Learning tasks.\n",
    "\n",
    "Even just in the context of classification, it provides many different standard algorithms to perform that task such as Nearest Neighbors, Decision Tree, Naive Bayes\n",
    "and many others. This [page](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py)\n",
    "provides a complete list and shows some interesting visualizations of how the different classification algorithms compare on three small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-it-gNTOuK4"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7djifpMOvm8"
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "* Create a classification model with scikit-learn.\n",
    "* Use scikit-learn to make classification predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiUF4EoxO-Vk"
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "* Introduction to Colab\n",
    "* Intermediate Python\n",
    "* Intermediate Pandas\n",
    "* Visualizations\n",
    "* Introduction to scikit-learn\n",
    "* Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXB_yHF7PIon"
   },
   "source": [
    "### Estimated Duration\n",
    "\n",
    "60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sPvH4sVPKms"
   },
   "source": [
    "### Grading Criteria\n",
    "\n",
    "Each exercise is worth 3 points. The rubric for calculating those points is:\n",
    "\n",
    "| Points | Description |\n",
    "|--------|-------------|\n",
    "| 0      | No attempt at exercise |\n",
    "| 1      | Attempted exercise, but code does not run |\n",
    "| 2      | Attempted exercise, code runs, but produces incorrect answer |\n",
    "| 3      | Exercise completed successfully |\n",
    "\n",
    "There is 1 exercise in this Colab so there are 3 points available. The grading scale will be 3 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1cjMb2GPREz"
   },
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUC2a6L5OqIl"
   },
   "source": [
    "Let's take a look at how to use Scikit-Learn to classify some data.\n",
    "\n",
    "### The Iris data set\n",
    "For this example, we will be using the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). This is a data set that was used in 1936 by British biologist and statistician Ronald Fisher to classify these flowers into one of three species of iris based on 4 measurements:\n",
    "- The length of the petals\n",
    "- The width of the petals\n",
    "- The length of the sepals (the green petal-looking bits that are found at the base of the petals\n",
    "- The width of the sepals\n",
    "\n",
    "![Iris](https://upload.wikimedia.org/wikipedia/commons/2/21/Blue_Iris.JPG)\n",
    "\n",
    "Conveniently, the iris data set is built-in to the Scikit-learn library so it is readily available to us. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "839qQ8bWalSl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/Users/dorishuang/anaconda3/lib/python3.6/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris_bunch = datasets.load_iris()\n",
    "iris_bunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zweFHsbUgEUL"
   },
   "source": [
    "Scikit-learn datasets are usually delivered in the form of a dictionary-like object called a `Bunch`. This `Bunch` contains the following fields:\n",
    "\n",
    "- *DESCR*: A string describing the dataset\n",
    "- *data*: An array containing the features we are using for classifying. In this case, the four measurements listed above for each of 150 plants\n",
    "- *feature_names*: Labels for the data\n",
    "- *filename*: the file that this data came from\n",
    "- *target*: the values that we are trying to classify these flowers into. In this case, since we are dealing with three species of iris, we use three numbers 0, 1 and 2 to identify each specie.\n",
    "- *target_names*: labels for the target values. In this case, 0 refers to the setosa specie, 1 to the versicolor specie and 2 to the virginica species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvjklYlhIafY"
   },
   "source": [
    "So that we don't get our species crossed, let us first create some named variables for each target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZL2nk8KQIViC"
   },
   "outputs": [],
   "source": [
    "SETOSA = 0\n",
    "VERSICOLOR = 1\n",
    "VIRGINICA = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqOmZ2ORJhTj"
   },
   "source": [
    "We'll also create a list of columns that we'll use for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMqyeotgJoAo"
   },
   "outputs": [],
   "source": [
    "FEATURES = iris_bunch['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQiAihz5DCfP"
   },
   "source": [
    "Next we will load the feature and target data into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4df5QLtC8kK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "5                  5.4               3.9                1.7               0.4   \n",
       "6                  4.6               3.4                1.4               0.3   \n",
       "7                  5.0               3.4                1.5               0.2   \n",
       "8                  4.4               2.9                1.4               0.2   \n",
       "9                  4.9               3.1                1.5               0.1   \n",
       "10                 5.4               3.7                1.5               0.2   \n",
       "11                 4.8               3.4                1.6               0.2   \n",
       "12                 4.8               3.0                1.4               0.1   \n",
       "13                 4.3               3.0                1.1               0.1   \n",
       "14                 5.8               4.0                1.2               0.2   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "16                 5.4               3.9                1.3               0.4   \n",
       "17                 5.1               3.5                1.4               0.3   \n",
       "18                 5.7               3.8                1.7               0.3   \n",
       "19                 5.1               3.8                1.5               0.3   \n",
       "20                 5.4               3.4                1.7               0.2   \n",
       "21                 5.1               3.7                1.5               0.4   \n",
       "22                 4.6               3.6                1.0               0.2   \n",
       "23                 5.1               3.3                1.7               0.5   \n",
       "24                 4.8               3.4                1.9               0.2   \n",
       "25                 5.0               3.0                1.6               0.2   \n",
       "26                 5.0               3.4                1.6               0.4   \n",
       "27                 5.2               3.5                1.5               0.2   \n",
       "28                 5.2               3.4                1.4               0.2   \n",
       "29                 4.7               3.2                1.6               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "120                6.9               3.2                5.7               2.3   \n",
       "121                5.6               2.8                4.9               2.0   \n",
       "122                7.7               2.8                6.7               2.0   \n",
       "123                6.3               2.7                4.9               1.8   \n",
       "124                6.7               3.3                5.7               2.1   \n",
       "125                7.2               3.2                6.0               1.8   \n",
       "126                6.2               2.8                4.8               1.8   \n",
       "127                6.1               3.0                4.9               1.8   \n",
       "128                6.4               2.8                5.6               2.1   \n",
       "129                7.2               3.0                5.8               1.6   \n",
       "130                7.4               2.8                6.1               1.9   \n",
       "131                7.9               3.8                6.4               2.0   \n",
       "132                6.4               2.8                5.6               2.2   \n",
       "133                6.3               2.8                5.1               1.5   \n",
       "134                6.1               2.6                5.6               1.4   \n",
       "135                7.7               3.0                6.1               2.3   \n",
       "136                6.3               3.4                5.6               2.4   \n",
       "137                6.4               3.1                5.5               1.8   \n",
       "138                6.0               3.0                4.8               1.8   \n",
       "139                6.9               3.1                5.4               2.1   \n",
       "140                6.7               3.1                5.6               2.4   \n",
       "141                6.9               3.1                5.1               2.3   \n",
       "142                5.8               2.7                5.1               1.9   \n",
       "143                6.8               3.2                5.9               2.3   \n",
       "144                6.7               3.3                5.7               2.5   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     species  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  \n",
       "10         0  \n",
       "11         0  \n",
       "12         0  \n",
       "13         0  \n",
       "14         0  \n",
       "15         0  \n",
       "16         0  \n",
       "17         0  \n",
       "18         0  \n",
       "19         0  \n",
       "20         0  \n",
       "21         0  \n",
       "22         0  \n",
       "23         0  \n",
       "24         0  \n",
       "25         0  \n",
       "26         0  \n",
       "27         0  \n",
       "28         0  \n",
       "29         0  \n",
       "..       ...  \n",
       "120        2  \n",
       "121        2  \n",
       "122        2  \n",
       "123        2  \n",
       "124        2  \n",
       "125        2  \n",
       "126        2  \n",
       "127        2  \n",
       "128        2  \n",
       "129        2  \n",
       "130        2  \n",
       "131        2  \n",
       "132        2  \n",
       "133        2  \n",
       "134        2  \n",
       "135        2  \n",
       "136        2  \n",
       "137        2  \n",
       "138        2  \n",
       "139        2  \n",
       "140        2  \n",
       "141        2  \n",
       "142        2  \n",
       "143        2  \n",
       "144        2  \n",
       "145        2  \n",
       "146        2  \n",
       "147        2  \n",
       "148        2  \n",
       "149        2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(iris_bunch['data'], columns=FEATURES)\n",
    "iris_df['species'] = iris_bunch['target']\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NjnaQldDJLl"
   },
   "source": [
    "Let's take a look at a description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNZ2fI-gDWMF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)     species  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mEyzlzmDkNR"
   },
   "source": [
    "There are 150 data points. No columns seem to be missing data and no values seem to be too far out of expected ranges. For example, there are no zero or negative lengths or widths and the length and width values fall well within what we'd expect for a tulip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7sOwA2U2EAJs"
   },
   "source": [
    "We are interested in using the measurement features to predict iris specie. Let's take a closer look at the values we'll be predicting.\n",
    "\n",
    "In this case we'll group by our 'species' feature and get a count of each species in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPb2c7WZD4P_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "species                                                           \n",
       "0                       50                50                 50   \n",
       "1                       50                50                 50   \n",
       "2                       50                50                 50   \n",
       "\n",
       "         petal width (cm)  \n",
       "species                    \n",
       "0                      50  \n",
       "1                      50  \n",
       "2                      50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.groupby('species').agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZQxmfnFkFw9"
   },
   "source": [
    "So we have 50 examples of each kind of iris. When we go to do a train/test split, we could rely on a random split, but that would lead to some cases where a type of iris never made it into the test set or that a type of iris was very over or under represented in one of the sets.\n",
    "\n",
    "Instead of relying on pure randomness in our split, we will perform a **stratified** split. This allows us to randomly split the data while keeping the ratio or iris types equivalent in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0BhenEm_sd0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test  = train_test_split(\n",
    "  iris_df,                      # split our iris dataframe\n",
    "  stratify=iris_df['species'],  # stratify by the species column   \n",
    "  test_size=0.2,                # 20% of the data should be held for testing\n",
    "  random_state=42               # hard-coded random state for repeatability in the example\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NUydHbohFk2w"
   },
   "source": [
    "We can now verify that the test set has roughly the same count of each type of iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkAEKt9dFpxV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "species                                                           \n",
       "0                       10                10                 10   \n",
       "1                       10                10                 10   \n",
       "2                       10                10                 10   \n",
       "\n",
       "         petal width (cm)  \n",
       "species                    \n",
       "0                      10  \n",
       "1                      10  \n",
       "2                      10  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('species').agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QS6Jp8nLFrP2"
   },
   "source": [
    "As does the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Wv2b5WeFtFD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "species                                                           \n",
       "0                       40                40                 40   \n",
       "1                       40                40                 40   \n",
       "2                       40                40                 40   \n",
       "\n",
       "         petal width (cm)  \n",
       "species                    \n",
       "0                      40  \n",
       "1                      40  \n",
       "2                      40  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('species').agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLgpKyKKjhz4"
   },
   "source": [
    "## Training a binary classifier\n",
    "\n",
    "Now that our data is prepared, our first classification task will be to create a classifier that distinguishes versicolor irises from the rest. In other words, rather than considering three classes of outcome (one for each species), we'll just care about two: \"versicolor\" and \"not versicolor\". This makes our classifier a binary classifier. This also requires us to use a different target than the one supplied with the data set.\n",
    "\n",
    "We will add an 'is_versicolor' column to our training and testing data. This new column will be the target for our binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLuAmn2dGDWK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "      <th>is_versicolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "8                  4.4               2.9                1.4               0.2   \n",
       "106                4.9               2.5                4.5               1.7   \n",
       "76                 6.8               2.8                4.8               1.4   \n",
       "9                  4.9               3.1                1.5               0.1   \n",
       "89                 5.5               2.5                4.0               1.3   \n",
       "\n",
       "     species  is_versicolor  \n",
       "8          0          False  \n",
       "106        2          False  \n",
       "76         1           True  \n",
       "9          0          False  \n",
       "89         1           True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train = train.assign(is_versicolor=train['species'] == VERSICOLOR)\n",
    "test = test.assign(is_versicolor=test['species'] == VERSICOLOR)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnZ9GAkwq72V"
   },
   "source": [
    "At this point, we could use several of Scikit-Learn's classifiers to classify our data but let's start with the [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) classifier, using the `SGDClassifier` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oseMj3ipq87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=500, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=2, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "binary_classifier = linear_model.SGDClassifier(\n",
    "  random_state=2, # Specifying random state allow us to get repeatable outcomes\n",
    "  tol=1e-3, \n",
    "  max_iter=500) \n",
    " \n",
    "binary_classifier.fit(train[FEATURES], train['is_versicolor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xep1QArVsei0"
   },
   "source": [
    "So how well did we do? Let's take a look at a test iris that we know is versicolor and see if we can correctly predict the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jsWrIpgsseNh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the first versicolor flower in our test dataset.\n",
    "flower = test[test['is_versicolor']].iloc[0]\n",
    "\n",
    "# Predict if that flower is a versicolor flower or not.\n",
    "binary_classifier.predict([flower[FEATURES]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gm_BpdB1thG7"
   },
   "source": [
    "So the classifier is able to identify this test flower as versicolor (True) but how can we evaluate how good our classifier is?\n",
    "\n",
    "## Evaluating our classifier\n",
    "\n",
    "One way to measure the accuracy of our classifier is to use cross-validation.\n",
    "Scikit-Learn makes that easy for us to do by providing the `cross_val_score` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjRKSX3ir0nk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72727273, 0.7       , 0.55555556])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "model_selection.cross_val_score(\n",
    "  binary_classifier, \n",
    "  test[FEATURES],\n",
    "  test['is_versicolor'],\n",
    "  cv=3,\n",
    "  scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yecT90FovLRA"
   },
   "source": [
    "63-70% seems like a pretty good result for our classifier. But it's not. Keep in mind that 66.6% of the flowers are not versicolor so a model that always predict False would get pretty close!\n",
    "\n",
    "It's important to remember when you're dealing with data that isn't evenly split between the classes that accuracy needs to factor in the distribution data. \n",
    "\n",
    "A classic example of this would be a medical test to detect a rare disease. A test that always returned False would be correct a high percentage of the time but completely fail to meet its purpose. See an illustration of this principle in [this article](https://www.scientificamerican.com/article/what-is-bayess-theorem-an/).\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "To look at how well our model is really doing, we need to consider the number of items that we correctly identify as being part of our class (true positives) or out of our class (true negatives) as well as the number that incorrectly identify as part of our class (false positives) and incorrectly identify as not part of our class (false negatives).\n",
    "\n",
    "A confusion matrix for a binary classifier is a matrix made up of those four values:\n",
    "\n",
    "<table>\n",
    "<tr><td>True negatives<td>False positives</tr>\n",
    "<tr><td>False negatives<td>True positives</tr>\n",
    "</table>\n",
    "\n",
    "Scikit-Learn makes it easy to get this matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RD0ZW-j0u1DV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  7],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predictions = model_selection.cross_val_predict(\n",
    "  binary_classifier,\n",
    "  test[FEATURES],\n",
    "  test['is_versicolor'],\n",
    "  cv=3\n",
    ")\n",
    "\n",
    "metrics.confusion_matrix(test['is_versicolor'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maQk30RouO6K"
   },
   "source": [
    "This matrix represents the behavior of our classifier:\n",
    "- Each row represents an actual class. In this case, the first row represents the 20 flowers that are not versicolor, the second represents the 10 flowers that are.\n",
    "- Each column represents a predicted class. In this case, the first column represents the 17 flowers that our classifier identified as not versicolor and  the second column represents the 3 flowers that were identified as versicolor\n",
    "\n",
    "We can then use these values to analyze our model. Two metrics that are commonly used to summarize the behavior of a classifier are precision (percentage of identified positives that are correct) and recall (percentage of positives that are correctly identified)\n",
    "\n",
    "Scikit-Learn also allows us to extract those values directly without going through the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5C76Kidt78B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 0.7\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(test['is_versicolor'], predictions)\n",
    "recall = metrics.recall_score(test['is_versicolor'], predictions)\n",
    "\n",
    "print(\"Precision: {}\\nRecall: {}\".format(precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7HCyjqwrwvx"
   },
   "source": [
    "Our model isn't looking so good anymore! \n",
    "\n",
    "We can try to increase precision or recall by adjusting the threshold that our classifier uses to determine whether an item belongs in a class. The classifier computes a value for each item in our data set and items that correspond to a value over the threshold are deemed to be in the class and those below the threshold are deemed not in the class. \n",
    "\n",
    "For example, if we use our test data we can get the scores that our classifier assigned to each flower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhtVlH1lryWm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-165.475368</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-151.946638</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-146.581511</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-142.789492</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-141.514447</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-131.181610</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-120.037381</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-113.695272</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-113.430327</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-110.466260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-108.512294</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-107.386280</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-106.690801</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-106.475533</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-102.385452</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-100.663313</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-98.328489</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-97.765482</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-95.165714</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-90.562303</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-85.197176</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-81.951605</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-80.312261</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-66.253642</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-57.096497</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-45.985386</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-35.089542</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-30.320541</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-25.501862</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-10.466260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Scores  Predictions  Actuals\n",
       "14  -165.475368        False    False\n",
       "141 -151.946638        False    False\n",
       "140 -146.581511        False    False\n",
       "22  -142.789492        False    False\n",
       "18  -141.514447        False    False\n",
       "10  -131.181610        False    False\n",
       "56  -120.037381        False     True\n",
       "147 -113.695272        False    False\n",
       "104 -113.430327        False    False\n",
       "138 -110.466260        False    False\n",
       "28  -108.512294        False    False\n",
       "51  -107.386280        False     True\n",
       "127 -106.690801        False    False\n",
       "7   -106.475533        False    False\n",
       "132 -102.385452        False    False\n",
       "49  -100.663313        False    False\n",
       "42   -98.328489        False    False\n",
       "20   -97.765482        False    False\n",
       "84   -95.165714        False     True\n",
       "77   -90.562303        False     True\n",
       "116  -85.197176        False    False\n",
       "75   -81.951605        False     True\n",
       "38   -80.312261        False    False\n",
       "63   -66.253642        False     True\n",
       "58   -57.096497        False     True\n",
       "107  -45.985386        False    False\n",
       "57   -35.089542        False     True\n",
       "69   -30.320541        False     True\n",
       "93   -25.501862        False     True\n",
       "134  -10.466260        False    False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What scores does or model generate?\n",
    "scores = binary_classifier.decision_function(test[FEATURES])\n",
    "\n",
    "# What predictions are made?\n",
    "predictions = binary_classifier.predict(test[FEATURES])\n",
    "\n",
    "# What is the actual value that should have been predicted?\n",
    "actuals = test['is_versicolor']\n",
    "\n",
    "# Store everything in a DataFrame\n",
    "df = pd.DataFrame({\n",
    "  'Scores': scores,\n",
    "  'Predictions': predictions,\n",
    "  'Actuals': actuals\n",
    "})\n",
    "\n",
    "# Output the data sorted by score\n",
    "df[['Scores', 'Predictions', 'Actuals']].sort_values(by=['Scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eq9rkpk9saQP"
   },
   "source": [
    "By default, Scikit-Learn uses a threshold of 0 so any flower that scores > 0 is going to be deemed part of versicolor.\n",
    "\n",
    "We can affect the decisions that the classifier is making by setting our own value for threshold.\n",
    "\n",
    "Scikit-Learn does not allow us to specify a different threshold when training the classifier but we can use the output of `decision_function` to make our own prediction with our own threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htGn6oyqsbNb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 55\n",
    "predictions = (scores > threshold)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfjxZ4hQuFSq"
   },
   "source": [
    "It's hard to tell if we're doing better since the samples are scrambled so we go back to precision and recall: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgDw89lsvGHY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorishuang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(test['is_versicolor'], predictions)\n",
    "recall = metrics.recall_score(test['is_versicolor'], predictions)\n",
    "\n",
    "print(\"Precision: {}\\nRecall: {}\".format(precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1nd-CtYAWV72"
   },
   "source": [
    "By lowering the threshold, we've improved the recall but lost some precision in our model. \n",
    "This is the usual trade-off when tweaking the threshold that we are using. We can visualize this trade-off by using the `precision_recall_curve` function which tries many different thresholds allowing us to plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lb9Vj3ySRZ6M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = model_selection.cross_val_predict(\n",
    "  binary_classifier, \n",
    "  test[FEATURES],\n",
    "  test['is_versicolor'],\n",
    "  cv=3,\n",
    "  method=\"decision_function\"\n",
    ")\n",
    "precisions, recalls, thresholds = metrics.precision_recall_curve(\n",
    "  test['is_versicolor'],\n",
    "  scores\n",
    ")\n",
    "\n",
    "plt.plot(thresholds, precisions[:-1], \"g--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recalls[:-1], \"r-\", label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHqDysloYQPv"
   },
   "source": [
    "This is (roughly) the kind of shape that we expect from this graph: as we increase the threshold, precision improves but recall drops. With a large dataset, this trend continues until precision reaches 100% and recall drops to 0.  But in this case, the data set is small enough that the overall graph looks strange when we zoom out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOJSyAOBY6_U"
   },
   "source": [
    "We see that raising the threshold ends up hurting precision as well as recall because a few incorrectly labelled flowers end up significantly hurting our metric.\n",
    "\n",
    "Another graph that we can use to evaluate our binary classifier is the _receiver operating characteristic_ (ROC) curve. This is a complex name for a relatively simple concept, the curve  plots the true positive rate (TPR which is just recall) against the false positive rate (FPR) for various threshold values. FPR is just (1 - the true negative rate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XPXD7w4ZNhr"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(test['is_versicolor'], scores)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRD6JpBibHUJ"
   },
   "source": [
    "The dotted line in this graph represents the behavior of a purely random classifier. The blue line represents the behavior of our classifier. The furthest away from the dotted line that our blue line is, the better our classifier. We can represent this \"furthest away\" concept numerically by measuring the area under the curve (AUC) using Scikit-Learn's built-in function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64EYzJ2abnet"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(test['is_versicolor'], scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LmPBdw5bwIA"
   },
   "source": [
    "A ROC AUC score of 1 indicates a perfect classifier, a score of 0.5 is equivalent to a random classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbIY3s1AxC30"
   },
   "source": [
    "## Classifying into multiple classes\n",
    "\n",
    "Often times, we are not just classifying into two classes (nails vs. screws or versicolor vs. not) but into multiple classes (nails vs. screws vs. bolts or the various types of irises). Since our dataset considers three different species of flowers, it would be great to be able to predict which species a flower belongs to.\n",
    "\n",
    "Random Forest classifiers and Naive Bayes classifiers are able to handle multiple classes directly but others (like our SGD classifier) are not able to do so. Instead, we must use multiple binary classifiers to break up our data into more than two classes.\n",
    "\n",
    "One way to do is to create one classifier like the one that we created earlier (versicolor vs. not) for each class that we want to support. In this case, it would mean 3 classifiers:\n",
    "- setosa vs. not\n",
    "- versicolor vs. not\n",
    "- virginica vs. not\n",
    "\n",
    "Determining the class for a test case is then a matter of running all three classifiers and selecting the one that gives the strongest positive score. This is called the one-versus-all (OvA) strategy.\n",
    "\n",
    "Alternatively, we could train a classifier to distinguish between every pair of classes that we are trying to classify our data into. This is called the one-versus-one (OvO) strategy. In our case, it would mean 3 classifiers again:\n",
    "- setosa vs. versicolor\n",
    "- setosa vs. virginica\n",
    "- versicolor vs. virginica\n",
    "\n",
    "Although we end up with the same number of classifier in our case of dealing with 3 classes, this is not the case when dealing with more classes. As the number of classes grows, the number of classifiers for OvO grows much more rapidly (O(n^2)) than OvA (O(n)). On the other hand, each classifier for OvO only requires the data from the two classes that it is considering in order to be built whereas each classifier for OvA must consider all the training data.\n",
    "\n",
    "Luckily, Scikit-Learn hides a lot of the complexity from us. In the case of our SGD classifier, it automatically detects that we are trying to do multiclass classification and uses the OvA strategy to create multiple classifiers for us and present us with the result of comparing the outcome of the 3 classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjgeCLB4wm9A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class_classifier = linear_model.SGDClassifier(random_state=1701, tol=1e-3)  \n",
    "multi_class_classifier.fit(train[FEATURES], train['species'])   # We're not using training_target_is_versicolor anymore\n",
    "multi_class_classifier.predict([flower[FEATURES]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTrtovnM58FN"
   },
   "source": [
    "The output is no longer a True/False value but a number representing the class that `flower` is predicted to be, in this case, 1 which indicates versicolor.\n",
    "\n",
    "We can pull back the curtain on what `SGDClassifier` is doing for us behind the scenes by using `decision_function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkzGAQrH5wSS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -29.39300012,   -1.43583729, -146.22923439]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  multi_class_classifier.decision_function([flower[FEATURES]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9sFbBb0DJuO"
   },
   "source": [
    "This array represents the three scores that the three binary classifiers gave `flower`. Clearly, number 1 was the strongest score so `flower` was identified as versicolor.\n",
    "\n",
    "We can now evaluate the accuracy of this new classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u3kF47acDBTT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.66666667, 0.66666667])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(multi_class_classifier, test[FEATURES], test['species'], cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-D1Yb_AEIpc"
   },
   "source": [
    "This is looking more promising than before. Although our odds of being randomly right have dropped to 33%, our model is able to predict the species of a flower with 66% accuracy.\n",
    "\n",
    "We can now compare that to how a Naive Bayes classifier would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1Vu3lzdEDIx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92857143, 0.97435897, 0.97435897])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "nb_classifier = naive_bayes.GaussianNB()\n",
    "nb_classifier.fit(train[FEATURES], train['species'])\n",
    "\n",
    "model_selection.cross_val_score(\n",
    "  nb_classifier,\n",
    "  train[FEATURES],\n",
    "  train['species'],\n",
    "  cv=3,\n",
    "  scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-NWoShLqcLq3"
   },
   "source": [
    "So it looks like a Naive Bayes classifier would do better for us for this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TaQgAcKkFWcV"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "In these exercises we will use another sample dataset provided by Scikit Learn. This dataset contain examples of handwritten digits. We'll create a binary classifier that determines if the digit we are provided is less than or equal to three.\n",
    "\n",
    "In order to do this we'll need to:\n",
    "\n",
    "1. Load the dataset from Scikit Learn.\n",
    "1. Convert the data from a `Bunch` to a `DataFrame`.\n",
    "1. Create a synthetic column that contains the value `True` if the digit is less than or equal to three and `False` otherwise.\n",
    "1. Split the data into a train and test set, stratifying by digit.\n",
    "1. Train an SGDClassifier.\n",
    "1. Graph precision vs. recall.\n",
    "1. Create custom predictions with our own hand-selected threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MoEaQTxEtNdt"
   },
   "source": [
    "## Exercise 1: Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeo65tX7l2VH"
   },
   "source": [
    "Scikit Learn has a built in dataset of handwritten digits. Look at the [load_digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) documentation and write code below to load the digits bunch into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uBz4lMIoZCoe"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcF9KyGJFB7w"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits_bunch =datasets.load_digits()\n",
    "digits_bunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxwAOVgouki0"
   },
   "source": [
    "## Exercise 2: Convert the Bunch to a Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0oXJKdFl5Ez"
   },
   "source": [
    "Though it isn't strictly necessary, we have been using Pandas DataFrames throughout most of our machine learning experience so far. To keep things consistent, write code below to create a Pandas DataFrame containing 65 columns of data. The first 64 columns are the pixel intensities for the images. The columns will be named '0' through '63'. Then add in a column called 'digit' that contains the target value for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LqDqpxrfZTvd"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IDl1eYaufwd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3     4     5     6    7    8     9  ...   55   56  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0   0.0  0.0  0.0   8.0  ...  0.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "5     0.0  0.0  12.0  10.0   0.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "6     0.0  0.0   0.0  12.0  13.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "7     0.0  0.0   7.0   8.0  13.0  16.0  15.0  1.0  0.0   0.0  ...  0.0  0.0   \n",
       "8     0.0  0.0   9.0  14.0   8.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "9     0.0  0.0  11.0  12.0   0.0   0.0   0.0  0.0  0.0   2.0  ...  0.0  0.0   \n",
       "10    0.0  0.0   1.0   9.0  15.0  11.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "11    0.0  0.0   0.0   0.0  14.0  13.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "12    0.0  0.0   5.0  12.0   1.0   0.0   0.0  0.0  0.0   0.0  ...  2.0  0.0   \n",
       "13    0.0  2.0   9.0  15.0  14.0   9.0   3.0  0.0  0.0   4.0  ...  0.0  0.0   \n",
       "14    0.0  0.0   0.0   8.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "15    0.0  5.0  12.0  13.0  16.0  16.0   2.0  0.0  0.0  11.0  ...  0.0  0.0   \n",
       "16    0.0  0.0   0.0   8.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  2.0  0.0   \n",
       "17    0.0  0.0   1.0   8.0  15.0  10.0   0.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "18    0.0  0.0  10.0   7.0  13.0   9.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "19    0.0  0.0   6.0  14.0   4.0   0.0   0.0  0.0  0.0   0.0  ...  2.0  0.0   \n",
       "20    0.0  0.0   3.0  13.0  11.0   7.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "21    0.0  0.0   0.0   2.0  16.0  16.0   2.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "22    0.0  0.0   8.0  16.0   5.0   0.0   0.0  0.0  0.0   1.0  ...  0.0  0.0   \n",
       "23    0.0  1.0   8.0  12.0  15.0  14.0   4.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "24    0.0  0.0   0.0   0.0  12.0   2.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "25    0.0  0.0  12.0   8.0   8.0   7.0   0.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "26    0.0  0.0   1.0  13.0  14.0   3.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "27    0.0  0.0   0.0   8.0  14.0  14.0   2.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "28    0.0  0.0  10.0  11.0   4.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "29    0.0  0.0   9.0  13.0   7.0   0.0   0.0  0.0  0.0   0.0  ...  2.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...   ...  ...  ...   ...  ...  ...  ...   \n",
       "1767  0.0  0.0   0.0   2.0  16.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1768  0.0  0.0   5.0  16.0  10.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1769  0.0  0.0   9.0  12.0  14.0   6.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1770  0.0  2.0  10.0  12.0  16.0   8.0   0.0  0.0  0.0   4.0  ...  0.0  0.0   \n",
       "1771  0.0  0.0   0.0   6.0  12.0   6.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1772  0.0  0.0   5.0  14.0  11.0   8.0   0.0  0.0  0.0   4.0  ...  0.0  0.0   \n",
       "1773  0.0  0.0   2.0  13.0  10.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1774  0.0  0.0   6.0  12.0  12.0   6.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1775  0.0  0.0   6.0  16.0  16.0   3.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1776  0.0  0.0  12.0  16.0  16.0   7.0   0.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "1777  0.0  0.0   0.0   2.0  14.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1778  0.0  0.0   0.0   1.0  13.0   8.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1779  0.0  0.0   3.0  10.0  16.0  16.0   4.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1780  0.0  3.0  14.0  15.0   6.0   0.0   0.0  0.0  0.0   7.0  ...  0.0  0.0   \n",
       "1781  0.0  0.0  10.0  16.0  14.0   5.0   0.0  0.0  0.0   2.0  ...  0.0  0.0   \n",
       "1782  0.0  1.0  10.0  13.0   2.0   0.0   0.0  0.0  0.0  10.0  ...  0.0  0.0   \n",
       "1783  0.0  0.0  15.0  13.0   1.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1784  0.0  0.0   1.0  10.0  14.0  13.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1785  0.0  1.0  10.0  16.0  15.0   2.0   0.0  0.0  0.0   1.0  ...  0.0  0.0   \n",
       "1786  0.0  0.0   4.0  14.0  15.0   6.0   0.0  0.0  0.0   5.0  ...  0.0  0.0   \n",
       "1787  0.0  0.0  10.0  16.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1788  0.0  0.0   0.0   1.0  12.0   6.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1789  0.0  0.0   8.0  16.0   3.0   0.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1790  0.0  0.0   5.0  12.0   8.0   0.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1791  0.0  0.0   0.0   3.0  15.0   4.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0   0.0  0.0  0.0   1.0  ...  0.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0   0.0  0.0  0.0   2.0  ...  0.0  0.0   \n",
       "\n",
       "       57    58    59    60    61    62   63  digit  \n",
       "0     0.0   6.0  13.0  10.0   0.0   0.0  0.0      0  \n",
       "1     0.0   0.0  11.0  16.0  10.0   0.0  0.0      1  \n",
       "2     0.0   0.0   3.0  11.0  16.0   9.0  0.0      2  \n",
       "3     0.0   7.0  13.0  13.0   9.0   0.0  0.0      3  \n",
       "4     0.0   0.0   2.0  16.0   4.0   0.0  0.0      4  \n",
       "5     0.0   9.0  16.0  16.0  10.0   0.0  0.0      5  \n",
       "6     0.0   1.0   9.0  15.0  11.0   3.0  0.0      6  \n",
       "7     0.0  13.0   5.0   0.0   0.0   0.0  0.0      7  \n",
       "8     0.0  11.0  16.0  15.0  11.0   1.0  0.0      8  \n",
       "9     0.0   9.0  12.0  13.0   3.0   0.0  0.0      9  \n",
       "10    0.0   1.0  10.0  13.0   3.0   0.0  0.0      0  \n",
       "11    0.0   0.0   1.0  13.0  16.0   1.0  0.0      1  \n",
       "12    0.0   3.0  11.0   8.0  13.0  12.0  4.0      2  \n",
       "13    2.0  12.0  12.0  13.0  11.0   0.0  0.0      3  \n",
       "14    0.0   0.0  10.0  15.0   4.0   0.0  0.0      4  \n",
       "15    4.0  15.0  16.0   2.0   0.0   0.0  0.0      5  \n",
       "16    0.0   0.0   7.0  15.0  16.0  11.0  0.0      6  \n",
       "17    0.0   0.0  11.0   9.0   0.0   0.0  0.0      7  \n",
       "18    0.0  11.0  14.0   5.0   0.0   0.0  0.0      8  \n",
       "19    0.0   7.0  16.0  16.0  13.0  11.0  1.0      9  \n",
       "20    0.0   2.0  12.0  13.0   4.0   0.0  0.0      0  \n",
       "21    0.0   0.0   2.0  12.0  15.0   4.0  0.0      1  \n",
       "22    0.0   7.0  12.0  12.0  12.0  13.0  1.0      2  \n",
       "23    0.0  14.0  15.0  11.0   2.0   0.0  0.0      3  \n",
       "24    0.0   0.0   0.0  12.0   8.0   0.0  0.0      4  \n",
       "25    0.0  11.0  14.0   9.0   0.0   0.0  0.0      5  \n",
       "26    0.0   3.0  12.0  15.0  14.0   7.0  0.0      6  \n",
       "27    0.0   0.0  12.0  13.0   1.0   0.0  0.0      7  \n",
       "28    0.0   8.0  14.0   7.0   1.0   0.0  0.0      8  \n",
       "29    0.0   7.0  12.0  12.0  12.0  11.0  0.0      9  \n",
       "...   ...   ...   ...   ...   ...   ...  ...    ...  \n",
       "1767  0.0   0.0   3.0  16.0   7.0   0.0  0.0      4  \n",
       "1768  0.0   4.0  15.0  16.0   8.0   1.0  0.0      0  \n",
       "1769  0.0  12.0  14.0   9.0   2.0   0.0  0.0      5  \n",
       "1770  2.0  14.0  16.0  12.0   9.0   0.0  0.0      3  \n",
       "1771  0.0   0.0   6.0  11.0  12.0   5.0  0.0      6  \n",
       "1772  0.0   7.0  15.0  12.0   5.0   0.0  0.0      9  \n",
       "1773  0.0   1.0  12.0  16.0  14.0   4.0  0.0      6  \n",
       "1774  0.0   2.0  11.0  10.0   4.0   0.0  0.0      1  \n",
       "1775  0.0  11.0  11.0   0.0   0.0   0.0  0.0      7  \n",
       "1776  0.0  10.0  12.0  12.0   4.0   0.0  0.0      5  \n",
       "1777  0.0   0.0   1.0  13.0   3.0   0.0  0.0      4  \n",
       "1778  0.0   0.0   0.0  15.0   7.0   0.0  0.0      4  \n",
       "1779  0.0   3.0  12.0   0.0   0.0   0.0  0.0      7  \n",
       "1780  4.0  15.0  13.0  12.0  11.0   1.0  0.0      2  \n",
       "1781  1.0  11.0  16.0  15.0   6.0   0.0  0.0      8  \n",
       "1782  0.0   9.0  13.0  11.0  10.0   9.0  0.0      2  \n",
       "1783  0.0  10.0  13.0  10.0   6.0   2.0  0.0      2  \n",
       "1784  0.0   0.0  12.0  14.0   4.0   0.0  0.0      5  \n",
       "1785  0.0  10.0  15.0   2.0   0.0   0.0  0.0      7  \n",
       "1786  0.0   4.0  13.0  15.0   9.0   0.0  0.0      9  \n",
       "1787  0.0   6.0  13.0  10.0   4.0   0.0  0.0      5  \n",
       "1788  0.0   0.0   0.0  14.0   9.0   0.0  0.0      4  \n",
       "1789  0.0  10.0  16.0  10.0   1.0   0.0  0.0      8  \n",
       "1790  0.0   6.0  12.0  12.0   3.0   0.0  0.0      8  \n",
       "1791  0.0   0.0   1.0  16.0   4.0   0.0  0.0      4  \n",
       "1792  0.0   2.0  14.0  15.0   9.0   0.0  0.0      9  \n",
       "1793  0.0   6.0  16.0  14.0   6.0   0.0  0.0      0  \n",
       "1794  0.0   2.0   9.0  13.0   6.0   0.0  0.0      8  \n",
       "1795  0.0   5.0  12.0  16.0  12.0   0.0  0.0      9  \n",
       "1796  1.0   8.0  12.0  14.0  12.0   1.0  0.0      8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "FEATURES = [x for x in range(64)]\n",
    "\n",
    "digits = pd.DataFrame(digits_bunch['data'], columns=FEATURES)\n",
    "digits['digit'] = digits_bunch['target']\n",
    "digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7B3VE9qvQqb"
   },
   "source": [
    "## Exercise 3: Create a Synthetic Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hkgTwUZKl8BG"
   },
   "source": [
    "Use the `assign` function to create a synthetic column called 'lt_eq_3' that contains `True` values if the target digit is three or less and `False` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSPMALoHZeKM"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPj2veJQvTik"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>digit</th>\n",
       "      <th>lt_eq_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3     4     5     6    7    8     9  ...   56   57  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0   0.0  0.0  0.0   8.0  ...  0.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "5     0.0  0.0  12.0  10.0   0.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "6     0.0  0.0   0.0  12.0  13.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "7     0.0  0.0   7.0   8.0  13.0  16.0  15.0  1.0  0.0   0.0  ...  0.0  0.0   \n",
       "8     0.0  0.0   9.0  14.0   8.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "9     0.0  0.0  11.0  12.0   0.0   0.0   0.0  0.0  0.0   2.0  ...  0.0  0.0   \n",
       "10    0.0  0.0   1.0   9.0  15.0  11.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "11    0.0  0.0   0.0   0.0  14.0  13.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "12    0.0  0.0   5.0  12.0   1.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "13    0.0  2.0   9.0  15.0  14.0   9.0   3.0  0.0  0.0   4.0  ...  0.0  2.0   \n",
       "14    0.0  0.0   0.0   8.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "15    0.0  5.0  12.0  13.0  16.0  16.0   2.0  0.0  0.0  11.0  ...  0.0  4.0   \n",
       "16    0.0  0.0   0.0   8.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "17    0.0  0.0   1.0   8.0  15.0  10.0   0.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "18    0.0  0.0  10.0   7.0  13.0   9.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "19    0.0  0.0   6.0  14.0   4.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "20    0.0  0.0   3.0  13.0  11.0   7.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "21    0.0  0.0   0.0   2.0  16.0  16.0   2.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "22    0.0  0.0   8.0  16.0   5.0   0.0   0.0  0.0  0.0   1.0  ...  0.0  0.0   \n",
       "23    0.0  1.0   8.0  12.0  15.0  14.0   4.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "24    0.0  0.0   0.0   0.0  12.0   2.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "25    0.0  0.0  12.0   8.0   8.0   7.0   0.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "26    0.0  0.0   1.0  13.0  14.0   3.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "27    0.0  0.0   0.0   8.0  14.0  14.0   2.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "28    0.0  0.0  10.0  11.0   4.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "29    0.0  0.0   9.0  13.0   7.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...   ...  ...  ...   ...  ...  ...  ...   \n",
       "1767  0.0  0.0   0.0   2.0  16.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1768  0.0  0.0   5.0  16.0  10.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1769  0.0  0.0   9.0  12.0  14.0   6.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1770  0.0  2.0  10.0  12.0  16.0   8.0   0.0  0.0  0.0   4.0  ...  0.0  2.0   \n",
       "1771  0.0  0.0   0.0   6.0  12.0   6.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1772  0.0  0.0   5.0  14.0  11.0   8.0   0.0  0.0  0.0   4.0  ...  0.0  0.0   \n",
       "1773  0.0  0.0   2.0  13.0  10.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1774  0.0  0.0   6.0  12.0  12.0   6.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1775  0.0  0.0   6.0  16.0  16.0   3.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1776  0.0  0.0  12.0  16.0  16.0   7.0   0.0  0.0  0.0   3.0  ...  0.0  0.0   \n",
       "1777  0.0  0.0   0.0   2.0  14.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1778  0.0  0.0   0.0   1.0  13.0   8.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1779  0.0  0.0   3.0  10.0  16.0  16.0   4.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1780  0.0  3.0  14.0  15.0   6.0   0.0   0.0  0.0  0.0   7.0  ...  0.0  4.0   \n",
       "1781  0.0  0.0  10.0  16.0  14.0   5.0   0.0  0.0  0.0   2.0  ...  0.0  1.0   \n",
       "1782  0.0  1.0  10.0  13.0   2.0   0.0   0.0  0.0  0.0  10.0  ...  0.0  0.0   \n",
       "1783  0.0  0.0  15.0  13.0   1.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1784  0.0  0.0   1.0  10.0  14.0  13.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1785  0.0  1.0  10.0  16.0  15.0   2.0   0.0  0.0  0.0   1.0  ...  0.0  0.0   \n",
       "1786  0.0  0.0   4.0  14.0  15.0   6.0   0.0  0.0  0.0   5.0  ...  0.0  0.0   \n",
       "1787  0.0  0.0  10.0  16.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1788  0.0  0.0   0.0   1.0  12.0   6.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1789  0.0  0.0   8.0  16.0   3.0   0.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1790  0.0  0.0   5.0  12.0   8.0   0.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1791  0.0  0.0   0.0   3.0  15.0   4.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0   0.0  0.0  0.0   1.0  ...  0.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0   1.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0   0.0  0.0  0.0   2.0  ...  0.0  1.0   \n",
       "\n",
       "        58    59    60    61    62   63  digit  lt_eq_3  \n",
       "0      6.0  13.0  10.0   0.0   0.0  0.0      0     True  \n",
       "1      0.0  11.0  16.0  10.0   0.0  0.0      1     True  \n",
       "2      0.0   3.0  11.0  16.0   9.0  0.0      2     True  \n",
       "3      7.0  13.0  13.0   9.0   0.0  0.0      3     True  \n",
       "4      0.0   2.0  16.0   4.0   0.0  0.0      4    False  \n",
       "5      9.0  16.0  16.0  10.0   0.0  0.0      5    False  \n",
       "6      1.0   9.0  15.0  11.0   3.0  0.0      6    False  \n",
       "7     13.0   5.0   0.0   0.0   0.0  0.0      7    False  \n",
       "8     11.0  16.0  15.0  11.0   1.0  0.0      8    False  \n",
       "9      9.0  12.0  13.0   3.0   0.0  0.0      9    False  \n",
       "10     1.0  10.0  13.0   3.0   0.0  0.0      0     True  \n",
       "11     0.0   1.0  13.0  16.0   1.0  0.0      1     True  \n",
       "12     3.0  11.0   8.0  13.0  12.0  4.0      2     True  \n",
       "13    12.0  12.0  13.0  11.0   0.0  0.0      3     True  \n",
       "14     0.0  10.0  15.0   4.0   0.0  0.0      4    False  \n",
       "15    15.0  16.0   2.0   0.0   0.0  0.0      5    False  \n",
       "16     0.0   7.0  15.0  16.0  11.0  0.0      6    False  \n",
       "17     0.0  11.0   9.0   0.0   0.0  0.0      7    False  \n",
       "18    11.0  14.0   5.0   0.0   0.0  0.0      8    False  \n",
       "19     7.0  16.0  16.0  13.0  11.0  1.0      9    False  \n",
       "20     2.0  12.0  13.0   4.0   0.0  0.0      0     True  \n",
       "21     0.0   2.0  12.0  15.0   4.0  0.0      1     True  \n",
       "22     7.0  12.0  12.0  12.0  13.0  1.0      2     True  \n",
       "23    14.0  15.0  11.0   2.0   0.0  0.0      3     True  \n",
       "24     0.0   0.0  12.0   8.0   0.0  0.0      4    False  \n",
       "25    11.0  14.0   9.0   0.0   0.0  0.0      5    False  \n",
       "26     3.0  12.0  15.0  14.0   7.0  0.0      6    False  \n",
       "27     0.0  12.0  13.0   1.0   0.0  0.0      7    False  \n",
       "28     8.0  14.0   7.0   1.0   0.0  0.0      8    False  \n",
       "29     7.0  12.0  12.0  12.0  11.0  0.0      9    False  \n",
       "...    ...   ...   ...   ...   ...  ...    ...      ...  \n",
       "1767   0.0   3.0  16.0   7.0   0.0  0.0      4    False  \n",
       "1768   4.0  15.0  16.0   8.0   1.0  0.0      0     True  \n",
       "1769  12.0  14.0   9.0   2.0   0.0  0.0      5    False  \n",
       "1770  14.0  16.0  12.0   9.0   0.0  0.0      3     True  \n",
       "1771   0.0   6.0  11.0  12.0   5.0  0.0      6    False  \n",
       "1772   7.0  15.0  12.0   5.0   0.0  0.0      9    False  \n",
       "1773   1.0  12.0  16.0  14.0   4.0  0.0      6    False  \n",
       "1774   2.0  11.0  10.0   4.0   0.0  0.0      1     True  \n",
       "1775  11.0  11.0   0.0   0.0   0.0  0.0      7    False  \n",
       "1776  10.0  12.0  12.0   4.0   0.0  0.0      5    False  \n",
       "1777   0.0   1.0  13.0   3.0   0.0  0.0      4    False  \n",
       "1778   0.0   0.0  15.0   7.0   0.0  0.0      4    False  \n",
       "1779   3.0  12.0   0.0   0.0   0.0  0.0      7    False  \n",
       "1780  15.0  13.0  12.0  11.0   1.0  0.0      2     True  \n",
       "1781  11.0  16.0  15.0   6.0   0.0  0.0      8    False  \n",
       "1782   9.0  13.0  11.0  10.0   9.0  0.0      2     True  \n",
       "1783  10.0  13.0  10.0   6.0   2.0  0.0      2     True  \n",
       "1784   0.0  12.0  14.0   4.0   0.0  0.0      5    False  \n",
       "1785  10.0  15.0   2.0   0.0   0.0  0.0      7    False  \n",
       "1786   4.0  13.0  15.0   9.0   0.0  0.0      9    False  \n",
       "1787   6.0  13.0  10.0   4.0   0.0  0.0      5    False  \n",
       "1788   0.0   0.0  14.0   9.0   0.0  0.0      4    False  \n",
       "1789  10.0  16.0  10.0   1.0   0.0  0.0      8    False  \n",
       "1790   6.0  12.0  12.0   3.0   0.0  0.0      8    False  \n",
       "1791   0.0   1.0  16.0   4.0   0.0  0.0      4    False  \n",
       "1792   2.0  14.0  15.0   9.0   0.0  0.0      9    False  \n",
       "1793   6.0  16.0  14.0   6.0   0.0  0.0      0     True  \n",
       "1794   2.0   9.0  13.0   6.0   0.0  0.0      8    False  \n",
       "1795   5.0  12.0  16.0  12.0   0.0  0.0      9    False  \n",
       "1796   8.0  12.0  14.0  12.0   1.0  0.0      8    False  \n",
       "\n",
       "[1797 rows x 66 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = digits.assign(lt_eq_3 = digits['digit']<=3)\n",
    "digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZpldSjTvlPH"
   },
   "source": [
    "## Exercise 4: Split the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FDL9P5N9l-HN"
   },
   "source": [
    "Use `train_test_split` to split 20% of the digits data off for testing. Stratify by digit so that you get a representative sample from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SP-KwUpNZ1Kc"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRRDdHyDvnMX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test  = train_test_split(\n",
    "  digits,                     \n",
    "  stratify=digits['digit'],  \n",
    "  test_size=0.2,              \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAA9T67jwBxy"
   },
   "source": [
    "## Exercise 5: Create and Fit a Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DztsQdmZmBrt"
   },
   "source": [
    "Create an instance of the `SGDClassifer`. Train the classifier on features '0' through '63' and target the 'lt_eq_3' column created earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FsACOwEaL-q"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1lkXY9DwEeV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=500, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=2, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "binary_classifier = linear_model.SGDClassifier(\n",
    "  random_state=2, # Specifying random state allow us to get repeatable outcomes\n",
    "  tol=1e-3, \n",
    "  max_iter=500) \n",
    " \n",
    "binary_classifier.fit(train[FEATURES], train['lt_eq_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4t8S7JCwn_k"
   },
   "source": [
    "## Exercise 6: Get Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCJZIqKamExd"
   },
   "source": [
    "Use the `cross_val_predict` to get scores for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPonNu2EauHT"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-r95ijqwvE2"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "scores = model_selection.cross_val_predict(\n",
    "  binary_classifier, \n",
    "  digits[FEATURES],\n",
    "  digits['lt_eq_3'],\n",
    "  cv=3,\n",
    "  method=\"decision_function\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tG6i68xqw4rT"
   },
   "source": [
    "## Exercise 7: Get Precision, Recall, and Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OL0r7rnsmG-A"
   },
   "source": [
    "Use `precision_recall_curve` to get precisions, recalls, and thresholds for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gcmoWrxa7pq"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xq_vMcwHw7Yt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.44171779, 0.44137508, 0.44164619, ..., 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " array([1.        , 0.99861111, 0.99861111, ..., 0.00277778, 0.00138889,\n",
       "        0.        ]),\n",
       " array([-1588.10667182, -1587.3019417 , -1587.02215098, ...,\n",
       "         3920.9378949 ,  3940.01123738,  4101.96248851]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "precisions, recalls, thresholds = metrics.precision_recall_curve(\n",
    "  digits['lt_eq_3'],\n",
    "  scores\n",
    ")\n",
    "precisions, recalls, thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MksAmL-AxJBD"
   },
   "source": [
    "## Exercise 8: Plot the Precision Recall Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDgDNr60mKAt"
   },
   "source": [
    "Use Matplotlib to plot the precision recall curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZVwu4elbHeB"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikE7cS1JxLp3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(thresholds, precisions[:-1], \"g--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recalls[:-1], \"r-\", label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipbputQtw1Q0"
   },
   "source": [
    "## Exercise 9: Make New Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-JhqUJBmNC-"
   },
   "source": [
    "Eyeballing the graph produced above, use a custom threshold to make new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "splXb1hgbWiA"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hegKVZDkxi6r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 250 # Change to a better thresold\n",
    "predictions = (scores > threshold)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFvFYaqCxqWy"
   },
   "source": [
    "## Exercise 10: Output New Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ILAsWdpmPSq"
   },
   "source": [
    "Based on your new predictions use `precision_score` and `recall_score` to print out the new precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qoRSMqFbjfx"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C72HClxCwf2T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8725806451612903\n",
      "Recall: 0.7513888888888889\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(digits['lt_eq_3'], predictions)\n",
    "recall = metrics.recall_score(digits['lt_eq_3'], predictions)\n",
    "\n",
    "print(\"Precision: {}\\nRecall: {}\".format(precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BU-kVEDyJkm"
   },
   "source": [
    "## Exercise 11: Multiclass Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYBvLLuYmR4G"
   },
   "source": [
    "Create and fit a multiclass classifier to attempt to distinguish each digit from each other from 0 to 9.\n",
    "\n",
    "Report its cross-value score for accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ym8ooazWbwqt"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tyg1w-0jKID"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82392027, 0.79966611, 0.83221477])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive_bayes\n",
    "from sklearn import naive_bayes\n",
    "multi_class_digit_classifier = naive_bayes.GaussianNB()\n",
    "nb_classifier.fit(train[FEATURES], train['digit'])\n",
    "\n",
    "cross_value_scores = model_selection.cross_val_score(\n",
    "  multi_class_digit_classifier,\n",
    "  digits[FEATURES],\n",
    "  digits['digit'],\n",
    "  cv=3,\n",
    "  scoring=\"accuracy\",)\n",
    "        \n",
    "cross_value_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgV8F9svx10w"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8986711 , 0.95325543, 0.89932886])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGDClassifier\n",
    "multi_class_digit_classifier = linear_model.SGDClassifier(tol=1e-3)  \n",
    "multi_class_digit_classifier.fit(train[FEATURES], train['digit'])  \n",
    "\n",
    "cross_value_scores = model_selection.cross_val_score(multi_class_digit_classifier, \n",
    "                                digits[FEATURES], digits['digit'], \n",
    "                                cv=3, scoring=\"accuracy\")\n",
    "cross_value_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5BvYN1BjQEK"
   },
   "source": [
    "## Exercise 12: Challenge (Ungraded) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQhSi3fhmUM1"
   },
   "source": [
    "As an optional exercise, try 4 different binary classifiers of your choice for the  \"less than or equal to 3\" or \"greater than 3\" problem. Graph the ROC curve for all 4 classifiers on the same plot to compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpxsRdBFb3E4"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6e7e-bCfj70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74457429, 0.75125209, 0.80801336])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "multi_class_digit_classifier_tree = DecisionTreeClassifier(max_depth=2)  \n",
    "multi_class_digit_classifier_tree.fit(train[FEATURES], train['lt_eq_3']) \n",
    "\n",
    "cross_value_scores_tree = model_selection.cross_val_score(multi_class_digit_classifier_tree, \n",
    "                                                     digits[FEATURES], digits['lt_eq_3'], \n",
    "                                                     cv=3, scoring=\"accuracy\")\n",
    "cross_value_scores_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmC6k1hD0b6S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95492487, 0.97829716, 0.97495826])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "multi_class_digit_classifier_KNN = KNeighborsClassifier(n_neighbors=2)  \n",
    "multi_class_digit_classifier_KNN.fit(train[FEATURES], train['lt_eq_3'])\n",
    "\n",
    "cross_value_scores_KNN = model_selection.cross_val_score(multi_class_digit_classifier_KNN, \n",
    "                                                     digits[FEATURES], digits['lt_eq_3'], \n",
    "                                                     cv=3, scoring=\"accuracy\")\n",
    "cross_value_scores_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D07aeEN71E_B"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88981636, 0.92654424, 0.86811352])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "multi_class_digit_classifier_SVC = SVC(kernel=\"linear\")  \n",
    "multi_class_digit_classifier_SVC.fit(train[FEATURES], train['lt_eq_3'])  \n",
    "\n",
    "cross_value_scores_SVC = model_selection.cross_val_score(multi_class_digit_classifier_SVC, \n",
    "                                                     digits[FEATURES], digits['lt_eq_3'], \n",
    "                                                     cv=3, scoring=\"accuracy\")\n",
    "cross_value_scores_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3kySknX1qaP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97161937, 0.98163606, 0.97829716])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "multi_class_digit_classifier_GPC = GaussianProcessClassifier()  \n",
    "multi_class_digit_classifier_GPC.fit(train[FEATURES], train['lt_eq_3']) \n",
    "\n",
    "cross_value_scores_GPC = model_selection.cross_val_score(multi_class_digit_classifier_GPC, \n",
    "                                                     digits[FEATURES], digits['lt_eq_3'], \n",
    "                                                     cv=3, scoring=\"accuracy\")\n",
    "cross_value_scores_GPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btvLsoxTYVGx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96494157, 0.97829716, 0.97328881])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "multi_class_digit_classifier_MLP = MLPClassifier()  \n",
    "multi_class_digit_classifier_MLP.fit(train[FEATURES], train['lt_eq_3'])  \n",
    "\n",
    "cross_value_scores_MLP = model_selection.cross_val_score(multi_class_digit_classifier_MLP, \n",
    "                                                     digits[FEATURES], digits['lt_eq_3'], \n",
    "                                                     cv=3, scoring=\"accuracy\")\n",
    "cross_value_scores_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyHXPd2VLm9Q"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_scores = model_selection.cross_val_predict(\n",
    "    multi_class_digit_classifier_tree,\n",
    "    digits[FEATURES], \n",
    "    digits['lt_eq_3'], \n",
    "    cv=3,\n",
    ")\n",
    "\n",
    "tree_fpr, tree_tpr, thresholds = metrics.roc_curve(digits['lt_eq_3'], tree_scores)\n",
    "\n",
    "KNN_scores = model_selection.cross_val_predict(\n",
    "    multi_class_digit_classifier_KNN,\n",
    "    digits[FEATURES], \n",
    "    digits['lt_eq_3'], \n",
    "    cv=3,\n",
    ")\n",
    "KNN_fpr, KNN_tpr, thresholds = metrics.roc_curve(digits['lt_eq_3'], KNN_scores)\n",
    "\n",
    "SVC_scores = model_selection.cross_val_predict(\n",
    "    multi_class_digit_classifier_SVC,\n",
    "    digits[FEATURES], \n",
    "    digits['lt_eq_3'], \n",
    "    cv=3,\n",
    ")\n",
    "SVC_fpr, SVC_tpr, thresholds = metrics.roc_curve(digits['lt_eq_3'], SVC_scores)\n",
    "\n",
    "GPC_scores = model_selection.cross_val_predict(\n",
    "    multi_class_digit_classifier_GPC,\n",
    "    digits[FEATURES], \n",
    "    digits['lt_eq_3'], \n",
    "    cv=3,\n",
    ")\n",
    "GPC_fpr, GPC_tpr, thresholds = metrics.roc_curve(digits['lt_eq_3'], GPC_scores)\n",
    "\n",
    "MLP_scores = model_selection.cross_val_predict(\n",
    "    multi_class_digit_classifier_MLP,\n",
    "    digits[FEATURES], \n",
    "    digits['lt_eq_3'], \n",
    "    cv=3,\n",
    ")\n",
    "MLP_fpr, MLP_tpr, thresholds = metrics.roc_curve(digits['lt_eq_3'], MLP_scores)\n",
    "\n",
    "plt.plot(tree_fpr, tree_tpr,'g-')\n",
    "plt.plot(KNN_fpr, KNN_tpr,'r-')\n",
    "plt.plot(SVC_fpr, SVC_tpr,'b-')\n",
    "plt.plot(GPC_fpr, GPC_tpr,'y-')\n",
    "plt.plot(MLP_fpr, MLP_tpr,'c-')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83PzCAt3ZW4t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9269103 , 0.94323873, 0.9295302 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "multi_class_digit_classifier_MLP = MLPClassifier()  \n",
    "multi_class_digit_classifier_MLP.fit(train[FEATURES], train['digit'])  \n",
    "\n",
    "cross_value_scores_MLP_digit = model_selection.cross_val_score(multi_class_digit_classifier_MLP, \n",
    "                                                     digits[FEATURES], digits['digit'], \n",
    "                                                     cv=3, scoring=\"accuracy\")\n",
    "cross_value_scores_MLP_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CcASlx4cjoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95847176, 0.96327212, 0.9647651 ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "multi_class_digit_classifier_KNN = KNeighborsClassifier(n_neighbors=2)  \n",
    "multi_class_digit_classifier_KNN.fit(train[FEATURES], train['digit'])\n",
    "\n",
    "cross_value_scores_KNN_digit = model_selection.cross_val_score(multi_class_digit_classifier_KNN, \n",
    "                                                     digits[FEATURES], digits['digit'], \n",
    "                                                     cv=3, scoring=\"accuracy\")\n",
    "cross_value_scores_KNN_digit"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "copyright"
   ],
   "name": "Huize Huang - T05-01 [00] Classification with scikit-learn [Colab]",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
