{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "copyright"
   },
   "source": [
    "#### Copyright 2019 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Xt6PXeVjxQN"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2hPzRb6j_CA"
   },
   "source": [
    "# Basic Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fsdfasdfsadfsd"
   },
   "source": [
    "In this project you will perform a basic classification task.\n",
    "You will apply what you learned about binary classification and tensorflow to implement a Kaggle project without much guidance. The challenge is to achieve a high accuracy score when trying to predict which passengers survived the Titanic crash. After building your model, you will upload your predictions to Kaggle and submit the score that you receive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "overview"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "learning-objectives"
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "* Define, build, train and evaluate a Linear Classifier model in TensorFlow.\n",
    "* Submit predictions to a Kaggle challenge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VZe4Xj9tyQRD"
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "* T05-09 Classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDzCkRNv8Kmz"
   },
   "source": [
    "## Titanic: Machine Learning from Disaster\n",
    "\n",
    "[Kaggle](https://www.kaggle.com) has a [dataset](https://www.kaggle.com/c/titanic/data) containing the passenger list for the Titanic voyage. The data contains passenger features such as age, gender, and ticket class, as well as whether or not they survived.\n",
    "\n",
    "Your job is to load the data and create a binary classifier using TensorFlow to determine if a passenger survived or not. Then, upload your predictions to Kaggle and submit your accuracy score at the end of this colab, along with a brief conclusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-U_zk4L_HpWJ"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxmnIepvmdCx"
   },
   "source": [
    "## Exercise 1: Create a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mntl2Njdme0h"
   },
   "source": [
    "**Graded** demonstrations of competency:\n",
    "\n",
    "1. Download the [dataset](https://www.kaggle.com/c/titanic/data).\n",
    "2. Load the data into this Colab.\n",
    "3. Look at the description of the [dataset](https://www.kaggle.com/c/titanic/data) to understand the columns.\n",
    "4. Explore the dataset. Ask yourself: are there any missing values? Do the data values make sense? Which features seem to be the most important? Are they highly correlated with each other?\n",
    "5. Prep the data (deal with missing values, drop unnecessary columns, transform the data if needed, etc).\n",
    "6. Split the data into testing and training set.\n",
    "7. Create a `tensorflow.estimator.LinearClassifier`.\n",
    "8. Train the classifier using an input function that feeds the classifier training data.\n",
    "9. Make predictions on the test data using your classifier.\n",
    "10. Find the accuracy, precision, and recall of your classifier.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LO8x9d6GHwgQ"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKgNoBuEm2h0"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "dataset_filename = \"./train.csv\"\n",
    "train_csv =pd.read_csv(dataset_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGuemCpFhRuv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zUhGq5Ig9HD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TCNIIL21jABO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydgFBDZLir_i"
   },
   "source": [
    "**Preprocessing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZ3DZ3R1juN0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    27.915709\n",
       "male      30.726645\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = train_csv.groupby('Sex')['Age'].mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjXkTpPnl59n"
   },
   "outputs": [],
   "source": [
    "train_csv['Embarked']=train_csv['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyveqcZujIrP"
   },
   "outputs": [],
   "source": [
    "total = train_csv.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7o6ei0oyHWK"
   },
   "outputs": [],
   "source": [
    "train_csv.Cabin = train_csv.Cabin.fillna('N')\n",
    "train_csv.Cabin = train_csv.Cabin.map(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qncNIOUxzB8T"
   },
   "outputs": [],
   "source": [
    "train_csv['Family'] = train_csv.Parch + train_csv.SibSp + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pVMr65y1uBx"
   },
   "outputs": [],
   "source": [
    "train_csv['Title'] = train_csv.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFQs-VxNleS6"
   },
   "outputs": [],
   "source": [
    "train_csv['Age']= train_csv.groupby(['Sex','Pclass'])['Age'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4ijh_I971Oj"
   },
   "outputs": [],
   "source": [
    "train_csv.update(train_csv['Age'].astype(int) / train_csv['Age'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7D022YmvoQtP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          891 non-null object\n",
      "Embarked       891 non-null object\n",
      "Family         891 non-null int64\n",
      "Title          891 non-null object\n",
      "dtypes: float64(2), int64(6), object(6)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHtjfX1ux-nf"
   },
   "outputs": [],
   "source": [
    "# train_csv.Cabin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLCtCOYmn-Ui"
   },
   "outputs": [],
   "source": [
    "# train_csv['Sex'] = train_csv['Sex'].astype('category').cat.codes\n",
    "# train_csv['Sex'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1R9fvUinIdW"
   },
   "outputs": [],
   "source": [
    "# train_csv['Embarked'] = train_csv['Embarked'].astype('category').cat.codes\n",
    "# train_csv['Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeXUMRc6IEfb"
   },
   "outputs": [],
   "source": [
    "# train_csv.Fare = train_csv.Fare.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csJi6KHdmPD1"
   },
   "source": [
    "# Create, Train, Test the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCtpup4ahz-G"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(\n",
    "  train_csv,\n",
    "  stratify = train_csv.Sex,\n",
    "  test_size=0.2,\n",
    "  random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbCq9IYRmcVd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    251\n",
       "male      461\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('Sex')['Sex'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2z4OddlmsZC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female     63\n",
       "male      116\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('Sex')['Sex'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_wjqisBsSqS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "CATEGORICAL_COLUMNS = ['Pclass','Sex', 'SibSp', 'Parch','Embarked','Family','Title']\n",
    "NUMERIC_COLUMNS = ['Age', 'Fare']\n",
    "columns = ['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare','Embarked','Family','Title']\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  vocabulary = train_df[feature_name].unique()\n",
    "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mruuflgOntNr"
   },
   "outputs": [],
   "source": [
    "class_count = len(train_df['Survived'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1SON6elpPzM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 14:40:15.497383 4712515008 deprecation_wrapper.py:119] From /Users/dorishuang/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:10: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "W0731 14:40:15.500555 4712515008 estimator.py:1811] Using temporary folder as model directory: /var/folders/0n/ctf3gvvx57z27lg3_l0nbxzh0000gn/T/tmpi_rc9j4p\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.estimator import LinearClassifier\n",
    "\n",
    "classifier = LinearClassifier(feature_columns=feature_columns, n_classes=class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KfYuMI_t9cq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0731 14:40:15.554804 4712515008 deprecation.py:323] From /Users/dorishuang/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0731 14:40:16.435414 4712515008 deprecation.py:323] From /Users/dorishuang/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0731 14:40:17.112155 4712515008 deprecation.py:323] From /Users/dorishuang/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x1281e5b70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.data import Dataset\n",
    "\n",
    "def training_input():\n",
    "  features = {}\n",
    "  feature_columns = ['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare','Embarked','Family','Title']\n",
    "\n",
    "  for feat in feature_columns:\n",
    "    features[feat] = train_df[feat]\n",
    " \n",
    "  labels = train_df['Survived']\n",
    "\n",
    "  training_ds = Dataset.from_tensor_slices((features, labels))\n",
    "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
    "  training_ds = training_ds.batch(100)\n",
    "  training_ds = training_ds.repeat(10)\n",
    "\n",
    "  return training_ds\n",
    "\n",
    "classifier.train(training_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJkXyNJqrfJL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0731 14:40:23.183722 4712515008 deprecation.py:323] From /Users/dorishuang/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "def testing_input():\n",
    "  features = {}\n",
    "  feature_columns = ['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare','Embarked','Family','Title']\n",
    "  for feat in feature_columns:\n",
    "    features[feat] = test_df[feat]\n",
    "\n",
    "  return Dataset.from_tensor_slices((features)).batch(1)\n",
    "\n",
    "predictions_iterator = classifier.predict(testing_input)\n",
    "predictions = [p['class_ids'][0] for p in predictions_iterator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s85goBEUrou4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8156424581005587\n",
      "0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(precision_score(test_df['Survived'], predictions, average='micro'))\n",
    "print(recall_score(test_df['Survived'], predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yXJCSsAdz-f0"
   },
   "source": [
    "## Exercise 2: Upload your predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ONevNjq2UXu"
   },
   "source": [
    "**Graded** demonstrations of competency:\n",
    "1. Download the test.csv file from Kaggle and re-run your model using all of the training data.\n",
    "2. Use this new test data to generate predictions using your model.\n",
    "3. Follow the instructions in the [evaluation section](https://www.kaggle.com/c/titanic/overview/evaluation) to output the preditions in the format of the gender_submission.csv file. Download the predictions file from your Colab and upload it to Kaggle.\n",
    "\n",
    "\n",
    "**Written Response**\n",
    "\n",
    "Write down your conclusion along with the score that you got from Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fijeUn4tIFCo"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dEWZUCnT9UkK"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "dataset_filename = \"./test.csv\"\n",
    "test_csv =pd.read_csv(dataset_filename)\n",
    "\n",
    "train_csv['Embarked']=train_csv['Embarked'].fillna('S')\n",
    "test_csv['Title'] = test_csv.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "test_csv['Family'] = test_csv.Parch + test_csv.SibSp + 1\n",
    "test_csv['Age']= test_csv.groupby(['Sex','Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "test_csv.update(test_csv['Age'].astype(int) / test_csv['Age'].max())\n",
    "\n",
    "def testing_input():\n",
    "  features = {}\n",
    "  feature_columns = ['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare','Embarked','Family','Title']\n",
    "  for feat in feature_columns:\n",
    "    features[feat] = test_csv[feat]\n",
    "\n",
    "  return Dataset.from_tensor_slices((features)).batch(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yd9WMlNQ4oJs"
   },
   "outputs": [],
   "source": [
    "predictions_test = classifier.predict(testing_input)\n",
    "predictions = [p['class_ids'][0] for p in predictions_test]\n",
    "test_csv['Survived'] = predictions\n",
    "df = pd.DataFrame(test_csv, columns= ['PassengerId', 'Survived'])\n",
    "df\n",
    "export_csv = df.to_csv ('./gender_submission.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRZni-CBVjFV"
   },
   "source": [
    "{### Your written response goes here. Make sure to include your Kaggle score. ###}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJGnaxju5dPy"
   },
   "source": [
    "**Kaggle Score**\n",
    "\n",
    "0.78468 - Age NaN filled according to sex and pclass median, scaled down. \n",
    "\n",
    "test train 80 20 split, features =  'Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare','Embarked','Family','Title'\n",
    "\n",
    "(https://drive.google.com/file/d/1OIPx5m6nnsAAQsh4uc3U6JKGVTXaeeVN/view?usp=sharing)\n",
    "\n",
    "0.77990\n",
    "\n",
    "0.77033\n",
    "\n",
    "0.76076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5xB_T1Wjy0s"
   },
   "source": [
    "*** The Conclusion ***\n",
    "\n",
    "First, we preprocess the data to fill in Embarked and Age missing values. We replace the missing age values with the median of the class according to sex and ticket class. Then we created two more features - family size and title. \n",
    "\n",
    "As we tried more features, some of the featuers improved our model, some of the features didn't. We tried to fill in Cabin and use it as one of the features, but it decreased our score since we were filling the large amount of missing data with one category. \n",
    "\n",
    "We also tried to play around with train, test split ratio, but it turned out  the 80-20 is the best way to not overfit. The added class we have for family size and title derived from name improved our model. We also stratified the split according to sex to make more precise predictions. \n",
    "\n",
    "Eventaully, we set on Pclass, Sex, Age, SibSp, Patch, Fare, Embarked, Family and Title with 80-20 train test split for our model. \n",
    "\n",
    "We tried not to incorprate our bias into the dataset while preprocessing the data and making the model. \n",
    "In the future, we want to test more models and see how they will preform differently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KdtnUJP2Uen"
   },
   "source": [
    "## Exercise 3: Improve your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C781-AwN4q9Z"
   },
   "source": [
    "The predictions returned by the LinearClassifer contain scoring and/or confidence information about why the decision was made to classify a passenger as a survivor or not. Find the number used to make the decision and manually play around with different thresholds to build a precision vs. recall chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5rYKVkgT8NL"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDEErS0f8oi7"
   },
   "outputs": [],
   "source": [
    "# # Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFFInD4j-VMc"
   },
   "source": [
    "## Exercise 4: Dig deeper (optional and ungraded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93t_PYx6-W_N"
   },
   "source": [
    "Check out the different approaches in [this kernel](https://www.kaggle.com/startupsci/titanic-data-science-solutions) (kernels are solutions or data exploration notebooks shared by other users).\n",
    "Try using a different approach and see if you can improve your results.\n",
    "\n",
    "Alternatively, you can try implementing a simple decision tree by hand, as in this [Udacity Project](https://github.com/juemura/machine-learning/blob/master/projects/titanic_survival_exploration/titanic_survival_exploration.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_tj2sXDIk7N"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhbZHXy-ImSj"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# feature_columns = ['Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare','Embarked','Family','Title']\n",
    "# X_train = train_df[feature_columns]\n",
    "# y_train = train_df['Survived']\n",
    "# X_test = test_df[feature_columns]\n",
    "# y_test = test_df['Survived']\n",
    "\n",
    "# clf = DecisionTreeClassifier(random_state=2)\n",
    "# clf.fit(X=X_train, y=y_train)\n",
    "# clf.score(X=X_test, y=y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "copyright"
   ],
   "name": "Huize Huang - T05-10 [00] Basic Classification Project [Colab].ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
