{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nicolas Decavel-Bueff - T06-06 [00] Image Classification Project [Colab].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "yFwKrxE38t9S"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yFwKrxE38t9S"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kpcrMDk48nqI",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bTZOeKjw8waH"
      },
      "source": [
        "# Image Classification Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pK5j0BXxrbfX"
      },
      "source": [
        "In this project, we will built an image classification model and use the model to identify if the image contain a particular object.  The outcome of the model will be true of false for each images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7fz_1lEAXeW2"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lbXXnlHyXiKa"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Use a classification toolkits (scikit-learn, TensorFlow, or Keras) and build an image classification model.\n",
        "* Prepare image data to the appropriate format and quality to be a suitable input to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M62dLnxpX6Le"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* Classification with scikit-learn\n",
        "* Classification with TensorFlow\n",
        "* Neural Networks\n",
        "* Image Classificaion with Keras\n",
        "* Image Manipulation with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IrPi5LSZYIrw"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "330 minutes (285 minutes working time, 45 minutes for presentations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r6RA-x2G2Fd4"
      },
      "source": [
        "### Deliverables\n",
        "\n",
        "1. A copy of this Colab notebook containing your code and responses to the ethical considerations below. The code should produce a functional labeled video.\n",
        "1. A group presentation. After everyone is done, we will ask each group to stand in front of the class and give a brief presentation about what they have done in this lab. The presentation can be a code walkthrough, a group discussion, a slide show, or any other means that conveys what you did over the course of the day and what you learned. If you do create any artifacts for your presentation, please share them in the class folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pzCWjL4DYLgf"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "This project is graded in separate sections that each contribute a percentage of the total score:\n",
        "\n",
        "1. Building and Using a Model (80%)\n",
        "1. Ethical Implications (10%)\n",
        "1. Project Presentation (10%)\n",
        "\n",
        "#### Building and Using a Model\n",
        "\n",
        "There are 6 demonstrations of competency listed in the problem statement below. Each competency is graded on a 3 point scale for a total of 18 available points. The following rubric will be used:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at the competency |\n",
        "| 1      | Attempted competency, but in an incorrect manner |\n",
        "| 2      | Attempted competency correctly, but sub-optimally |\n",
        "| 3      | Successful demonstration of competency |\n",
        "\n",
        "\n",
        "#### Ethical Implications\n",
        "\n",
        "There are six questions in the **Ethical Implications** secion. Each question is worth 2 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at question or answer was off-topic or didn't make sense |\n",
        "| 1      | Question was answered, but answer missed important considerations  |\n",
        "| 2      | Answer adequately considered ethical implications |\n",
        "\n",
        "#### Project Presentation\n",
        "\n",
        "The project presentation will be graded on participation. All members of a team should actively participate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_yACB56w2JVk"
      },
      "source": [
        "## Team\n",
        "\n",
        "Please enter your team members names in the placeholders in this text area:\n",
        "\n",
        "*   Sarah\n",
        "*   Nicolas\n",
        "*   Huize\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YTVUYxPwcHhp"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LdIOgOHP1ces"
      },
      "source": [
        "## Exercise 1: Coding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jhTEOK1ZmqN8"
      },
      "source": [
        "There are very few more important questions in life than \"[Hot dog or not hot dog?](https://www.youtube.com/watch?v=ACmydtFDTGs)\". For this workshop you will be tasked with creating a machine learning model that can **take an input image and determine if the image is of a hot dog or not a hot dog**.\n",
        "\n",
        "Train your model with the [Kaggle Hot Dog/Not Hot Dog](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/data) data set. Feel free to [do some background research](https://medium.com/@timanglade/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3) on the topic.\n",
        "\n",
        "We have looked at regression, classification, and clustering models. We have used the Scikit Learn, TensorFlow, and Keras toolkits. Feel free to use the model and toolkit that you feel is the most appropriate.\n",
        " \n",
        "**Graded** demonstrations of competency:\n",
        "1. Pick a classification toolkit (eg: scikit-learn, TensorFlow or Keras) and provide jusitifaction for your choice. \n",
        "1. Obtain, prepare and load the dataset.\n",
        "1. Define and train a classification model.\n",
        "1. Test and evaluation your classification model. \n",
        "1. Apply your classification model to an image sourced from outside the Kaggle dataset. \n",
        "1. Test multiple models and/or sets of hyper-parameters and record the results. \n",
        "  \n",
        "Some tips:\n",
        " \n",
        "* Think about how to pre-process the images prior to use them as training data.  Should you train with images in color or grayscale, how many pixels should the image contains, etc. Clearly explain the reasoning for all of your choices in your Colab. \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7XM35vYWSbim"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ylKm3xZmTQE",
        "colab": {}
      },
      "source": [
        "# Your code goes here\n",
        "import altair as alt\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import seaborn as sns\n",
        "from google.colab import files \n",
        "import cv2 as cv \n",
        "\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('hot-dog-not-hot-dog.zip', 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()\n",
        "\n",
        "#Use attached zip file (splits data into train, validation, and testing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUzEQbZUrxWv",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28jHQhfxil40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import cv2 as cv\n",
        "\n",
        "train_images = [cv.imread(file) for file in glob.glob('hot-dog-not-hot-dog/train/hot_dog/*.jpg')]\n",
        "\n",
        "train_labels = np.ones(len(train_images))\n",
        "\n",
        "train_images_no = [cv.imread(file) for file in glob.glob('hot-dog-not-hot-dog/train/not_hot_dog/*.jpg')]\n",
        "\n",
        "train_no_labels = np.zeros(len(train_images_no))\n",
        "\n",
        "train_images = train_images + train_images_no\n",
        "train_labels = np.concatenate((train_labels, train_no_labels), axis = 0)\n",
        "print('image length:' + str(len(train_images)))\n",
        "print('label length:' + str(len(train_labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5tKCtdoqJiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.DataFrame({'label': train_labels, 'images': list(train_images)}, columns=['label', 'images'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s1n_65Jr9fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = [cv.imread(file) for file in glob.glob('hot-dog-not-hot-dog/test/hot_dog/*.jpg')]\n",
        "\n",
        "test_labels = np.ones(len(test_images))\n",
        "\n",
        "test_images_no = [cv.imread(file) for file in glob.glob('hot-dog-not-hot-dog/test/not_hot_dog/*.jpg')]\n",
        "\n",
        "test_no_labels = np.zeros(len(test_images_no))\n",
        "\n",
        "test_images = test_images + test_images_no\n",
        "test_labels = np.concatenate((test_labels, test_no_labels), axis = 0)\n",
        "print('image length:' + str(len(test_images)))\n",
        "print('label length:' + str(len(test_labels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6h5nmE2sf7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.DataFrame({'label': test_labels, 'images': list(test_images)}, columns=['label', 'images'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQwbz4StIRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check to see what the average size of the training dataset is\n",
        "width = []\n",
        "height = []\n",
        "for i in train_df.images:\n",
        "  width.append(i.shape[1])\n",
        "  height.append(i.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6nw5n2f07WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "width = width\n",
        "\n",
        "print(Counter(width).keys()) # equals to list(set(words))\n",
        "print(Counter(width).values()) # counts the elements' frequency  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmJL5Y9P07u5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "height = height\n",
        "\n",
        "print(Counter(height).keys()) # equals to list(set(words))\n",
        "print(Counter(height).values()) # counts the elements' frequency"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx6tfKS41Jt3",
        "colab_type": "text"
      },
      "source": [
        "Bring everything to 300x300 by adding padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsS7oJ-E1ssU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad(image):\n",
        "  height = image.shape[0]\n",
        "  width = image.shape[1]\n",
        "\n",
        "  left_pad, right_pad, top_pad, bottom_pad = 0, 0, 0, 0\n",
        "  if height > width:\n",
        "    left_pad = int((height-width) / 2)\n",
        "    right_pad = height-width-left_pad\n",
        "  elif width > height:\n",
        "    top_pad = int((width-height) / 2)\n",
        "    bottom_pad = width-height-top_pad\n",
        "\n",
        "  img_square = cv.copyMakeBorder(\n",
        "      image,\n",
        "      top_pad,\n",
        "      bottom_pad,\n",
        "      left_pad,\n",
        "      right_pad,\n",
        "      cv.BORDER_CONSTANT,\n",
        "      value=(255,255,255))\n",
        "  return img_square"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYkK-8LlkYDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(train_df.images[0])\n",
        "train_df.images[0][:,:,2] =  0.2989*train_df.images[0][:,:,0] +  0.5870*train_df.images[0][:,:,1] + 0.1140*train_df.images[0][:,:,2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rms7VFEk5Dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(train_df.images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZJi7QQOh-dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toGray(image):\n",
        "    # toGray converts RGB values to grayscale values by forming a weighted sum of the R, G, and B components:\n",
        "    # 0.2989 * R + 0.5870 * G + 0.1140 * B \n",
        "    # source: https://www.mathworks.com/help/matlab/ref/rgb2gray.html\n",
        "    image[:,:,0] = 0.2989*image[:,:,0] +  0.5870*image[:,:,1] + 0.1140*image[:,:,2]\n",
        "    image[:,:,1] = 0.2989*image[:,:,0] +  0.5870*image[:,:,1] + 0.1140*image[:,:,2]\n",
        "    image[:,:,2] = 0.2989*image[:,:,0] +  0.5870*image[:,:,1] + 0.1140*image[:,:,2]\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVQzUe99j007",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(image):\n",
        "  image =toGray(image)\n",
        "  image = pad(image)\n",
        "  image_scaled = cv.resize(image, (100, 100))\n",
        "  #image_scaled = np.true_divide(image_scaled, 255.0)\n",
        "  #print(image_scaled.shape)\n",
        "  return image_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ioy77tm2a7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.images = train_df.images.apply(lambda x: preprocess_image(x))\n",
        "#print(plt.imshow(train_df.images[1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8ByP1uOdYvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmPcHsbL5bML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.images = test_df.images.apply(lambda x: preprocess_image(x))\n",
        "# print(plt.imshow(test_df.images[1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zz5EFB719n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TPyeTPb2FKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb575DLGiw2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "model = tf.keras.Sequential([\n",
        "    \n",
        "\n",
        "    layers.Conv2D(32,(3,3),\n",
        "       input_shape=(100,100,3),\n",
        "       activation = 'relu'\n",
        "    ),\n",
        "    \n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        " \n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "\n",
        "    layers.Dense(512, activation = tf.nn.relu),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Dense(2, activation='softmax')\n",
        " \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5s33VKs2pmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "model.compile(\n",
        "    \n",
        "    # Specify loss function\n",
        "    loss=keras.losses.binary_crossentropy,\n",
        "    \n",
        "    # Specify optimizer\n",
        "    optimizer= tf.keras.optimizers.Adam(lr=1e-4),\n",
        "    \n",
        "    # Specify metrics\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-47gSlp2s5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.3,\n",
        "        zoom_range=0.4,\n",
        "        rotation_range=90,\n",
        "        horizontal_flip=True,\n",
        "        preprocessing_function = preprocess_image\n",
        ")\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function = preprocess_image)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './hot-dog-not-hot-dog/train',  # this is the target directory\n",
        "        target_size=(100, 100),  # all images will be resized to 100x100\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  # since we use binary_crossentropy loss, we need categorical labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        './hot-dog-not-hot-dog/validation',\n",
        "        target_size=(100, 100),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        './hot-dog-not-hot-dog/test',\n",
        "        target_size=(100, 100),\n",
        "        batch_size=batch_size, \n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv6taXGu24Fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=15,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=15\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw9dXa5SEMhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate_generator(generator=test_generator,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNDkcG6tesL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'(0.3,0.4 : .57) 10 epochs'\n",
        "'(0.3,0.4 : .62) 20 epochs'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}